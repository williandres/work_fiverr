{"cells":[{"cell_type":"markdown","metadata":{"id":"ktFg2jj3jTE6"},"source":["# ACTIVIDAD DE CLASIFICACIÓN DE TEXTO"]},{"cell_type":"markdown","metadata":{"id":"MZ-OuW5DiLJs"},"source":["En esta actividad vamos a trabajar en clasificar textos. Se recorrerá todo el proceso desde traer el dataset hasta proceder a dicha clasificación. Durante la actividad se llevarán a cabo muchos procesos como la creación de un vocabulario, el uso de embeddings y la creación de modelos.\n","\n","Las cuestiones presentes en esta actividad están basadas en un Notebook creado por François Chollet, uno de los creadores de Keras y autor del libro \"Deep Learning with Python\".\n","\n","En este Notebook se trabaja con el dataset \"Newsgroup20\" que contiene aproximadamente 20000 mensajes que pertenecen a 20 categorías diferentes.\n","\n","El objetivo es entender los conceptos que se trabajan y ser capaz de hacer pequeñas experimentaciones para mejorar el Notebook creado."]},{"cell_type":"markdown","metadata":{"id":"hytURWLLjZvT"},"source":["# Librerías"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DbxRuvOwkzSs"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"markdown","metadata":{"id":"PXfYbCflkQYy"},"source":["# Descarga de Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e-1ZhOf3lB_A"},"outputs":[],"source":["data_path = keras.utils.get_file(\n","    \"news20.tar.gz\",\n","    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n","    untar=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3ygvoWhlCYj"},"outputs":[],"source":["import os\n","import pathlib\n","\n","#Estructura de directorios del dataset\n","data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n","dirnames = os.listdir(data_dir)\n","print(\"Number of directories:\", len(dirnames))\n","print(\"Directory names:\", dirnames)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rs2Hl3yh3YtQ"},"outputs":[],"source":["print(data_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OG8rjgOFlcaV"},"outputs":[],"source":["#Algunos archivos de la categoria \"com.graphics\"\n","fnames = os.listdir(data_dir / \"comp.graphics\")\n","print(\"Number of files in comp.graphics:\", len(fnames))\n","print(\"Some example filenames:\", fnames[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ox6s6z9lgps"},"outputs":[],"source":["#Ejemplo de un texto de la categoría \"com.graphics\"\n","print(open(data_dir / \"comp.graphics\" / \"37261\").read())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vUbbjI8plaG0"},"outputs":[],"source":["#Algunos archivos de la categoria \"talk.politics.misc\"\n","fnames = os.listdir(data_dir / \"talk.politics.misc\")\n","print(\"Number of files in talk.politics.misc:\", len(fnames))\n","print(\"Some example filenames:\", fnames[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izZGWhpklCbI"},"outputs":[],"source":["#Ejemplo de un texto de la categoría \"talk.politics.misc\"\n","print(open(data_dir / \"talk.politics.misc\" / \"178463\").read())"]},{"cell_type":"code","source":["list_all_dir = [\n","    'alt.atheism',\n","    'comp.graphics',\n","    'comp.sys.mac.hardware',\n","    'comp.windows.x',\n","    'misc.forsale',\n","    'rec.autos',\n","    'rec.sport.baseball',\n","    'rec.sport.hockey',\n","    'sci.crypt',\n","    'sci.med',\n","    'sci.space',\n","    'soc.religion.christian',\n","    'talk.politics.guns',\n","    'talk.politics.misc',\n","    'talk.religion.misc'\n","]"],"metadata":{"id":"065tHPFg3aBq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"33Ay5U6blCd1"},"outputs":[],"source":["samples = []\n","labels = []\n","class_names = []\n","class_index = 0\n","for dirname in list_all_dir:\n","    class_names.append(dirname)\n","    dirpath = data_dir / dirname\n","    fnames = os.listdir(dirpath)\n","    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n","    for fname in fnames:\n","        fpath = dirpath / fname\n","        f = open(fpath, encoding=\"latin-1\")\n","        content = f.read()\n","        lines = content.split(\"\\n\")\n","        lines = lines[10:]\n","        content = \"\\n\".join(lines)\n","        samples.append(content)\n","        labels.append(class_index)\n","    class_index += 1\n","\n","print(\"Classes:\", class_names)\n","print(\"Number of samples:\", len(samples))"]},{"cell_type":"markdown","metadata":{"id":"n2pmvE6gMcxT"},"source":["# Mezclando los datos para separarlos en Traning y Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DYX7x-k_lCgZ"},"outputs":[],"source":["# Shuffle the data\n","seed = 1337\n","rng = np.random.RandomState(seed)\n","rng.shuffle(samples)\n","rng = np.random.RandomState(seed)\n","rng.shuffle(labels)\n","keras.utils.set_random_seed(seed)\n","\n","# Extract a training & validation split\n","validation_split = 0.2\n","num_validation_samples = int(validation_split * len(samples))\n","train_samples = samples[:-num_validation_samples]\n","val_samples = samples[-num_validation_samples:]\n","train_labels = labels[:-num_validation_samples]\n","val_labels = labels[-num_validation_samples:]"]},{"cell_type":"markdown","metadata":{"id":"IktOtKfpNx8E"},"source":["# Tokenización de las palabras con TextVectorization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QjHgQPX8lCjO"},"outputs":[],"source":["from tensorflow.keras.layers import TextVectorization\n","vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n","text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n","vectorizer.adapt(text_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vIWC37s5smZ4"},"outputs":[],"source":["vectorizer.get_vocabulary()[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vit8TPqTvmwS"},"outputs":[],"source":["len(vectorizer.get_vocabulary())"]},{"cell_type":"markdown","metadata":{"id":"2O-FXA9wPVkg"},"source":["# Viendo la salida de Vectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rseIF0fLmyJ0"},"outputs":[],"source":["output = vectorizer([[\"the cat sat on the mat\"]])\n","output.numpy()[0, :6]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wsr4AQtBFArV"},"outputs":[],"source":["output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SL5ag8UamzwL"},"outputs":[],"source":["voc = vectorizer.get_vocabulary()\n","word_index = dict(zip(voc, range(len(voc))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08v8SKcsn3lf"},"outputs":[],"source":["test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n","[word_index[w] for w in test]"]},{"cell_type":"markdown","metadata":{"id":"1eBhadrvOTNZ"},"source":["# Tokenización de los datos de entrenamiento y validación"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W26LUr2dKTOj"},"outputs":[],"source":["x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n","x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n","\n","y_train = np.array(train_labels)\n","y_val = np.array(val_labels)"]},{"cell_type":"markdown","metadata":{"id":"q3QVIb84Olda"},"source":["# Creación y entrenamiento del modelo. Red Neuronal Clásica"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9VxI-i69cdB"},"outputs":[],"source":["modeloClasico = keras.models.Sequential()\n","modeloClasico.add(keras.layers.Embedding(20000, 10, input_length=200))\n","modeloClasico.add(keras.layers.Flatten())\n","modeloClasico.add(keras.layers.Dense(512, activation='relu'))\n","modeloClasico.add(keras.layers.Dropout(0.3))\n","modeloClasico.add(keras.layers.Dense(20, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nEXXWuhx3YtX"},"outputs":[],"source":["modeloClasico.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","modeloClasico.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n","modeloClasico.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))\n","print(modeloClasico.summary())"]},{"cell_type":"markdown","metadata":{"id":"v4x_4eXJVrnX"},"source":["# Evaluación"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgg7KnoioNYc"},"outputs":[],"source":["string_input = keras.Input(shape=(1,), dtype=\"string\")\n","x = vectorizer(string_input)\n","preds = modeloClasico(x)\n","end_to_end_model = keras.Model(string_input, preds)\n","\n","probabilities = end_to_end_model.predict(\n","    [[\"this message is about computer graphics and 3D modeling\"]]\n",")\n","\n","class_names[np.argmax(probabilities[0])]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R-EXfK6qoSAd"},"outputs":[],"source":["probabilities = end_to_end_model.predict(\n","    [[\"politics and federal courts law that people understand with politician and elects congressman\"]]\n",")\n","\n","class_names[np.argmax(probabilities[0])]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QByfYDv4rGqv"},"outputs":[],"source":["probabilities = end_to_end_model.predict(\n","    [[\"we are talking about religion\"]]\n",")\n","\n","class_names[np.argmax(probabilities[0])]"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}